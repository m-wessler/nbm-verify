{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import pygrib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import multiprocessing as mp\n",
    "\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "nbm_dir = '/scratch/general/lustre/u1070830/nbm/'\n",
    "urma_dir = '/scratch/general/lustre/u1070830/urma/'\n",
    "tmp_dir = '/scratch/general/lustre/u1070830/tmp/'\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "nbm_shape = (1051, 1132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_fhr(nbm_file, xthreshold, xinterval, returned=False):\n",
    "    \n",
    "    # WE NEED TO MATCH URMA IN HERE IF WE CAN! \n",
    "        \n",
    "    try:\n",
    "        with pygrib.open(nbm_file) as grb:\n",
    "\n",
    "            msgs = grb.read()\n",
    "            if len(msgs) > 0:\n",
    "\n",
    "                _init = nbm_file.split('/')[-2:]\n",
    "                init = datetime.strptime(\n",
    "                    _init[0] + _init[1].split('.')[1][1:-1], \n",
    "                    '%Y%m%d%H')\n",
    "\n",
    "                if init.hour % 6 != 0:\n",
    "                    init -= timedelta(hours=1)\n",
    "\n",
    "                lats, lons = grb.message(1).latlons()\n",
    "\n",
    "                valid = datetime.strptime(\n",
    "                    str(msgs[0].validityDate) + '%02d'%msgs[0].validityTime, \n",
    "                    '%Y%m%d%H%M')\n",
    "\n",
    "                step = valid - init\n",
    "                lead = int(step.days*24 + step.seconds/3600)\n",
    "\n",
    "                tmpfile = tmp_dir + '%02dprobX%s_%s_f%03d'%(xinterval, str(xthreshold).replace('.', 'p'), init.strftime('%Y%m%d%H'), lead)\n",
    "\n",
    "                if not os.path.isfile(tmpfile + '.npy'):\n",
    "                    print(nbm_file.split('/')[-2:])\n",
    "\n",
    "                    for msg in msgs:\n",
    "\n",
    "                        if 'Probability of event above upper limit' in str(msg):\n",
    "\n",
    "                            interval = msg['stepRange'].split('-')\n",
    "                            interval = int(interval[1]) - int(interval[0])\n",
    "\n",
    "                            threshold = msg.upperLimit\n",
    "\n",
    "                            if ((threshold == xthreshold)&(interval == xinterval)):\n",
    "\n",
    "                                returned = True\n",
    "                                agg_data = np.array((init, valid, lead, msg.values), dtype=object)\n",
    "                                np.save(tmpfile, agg_data, allow_pickle=True)\n",
    "                                return agg_data\n",
    "\n",
    "                    if not returned:\n",
    "\n",
    "                        agg_data = np.array((init, valid, lead, np.full(nbm_shape, fill_value=np.nan)), dtype=object)\n",
    "                        np.save(tmpfile, agg_data, allow_pickle=True)\n",
    "                        return agg_data\n",
    "\n",
    "                else:\n",
    "                    print(nbm_file.split('/')[-2:], 'from file')\n",
    "                    return np.load(tmpfile + '.npy', allow_pickle=True)\n",
    "\n",
    "            else:\n",
    "                print('%s: No grib messages'%nbm_file.split('/')[-2:])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass data label to the extractor to pull out the variable we care about\n",
    "# Do these one at a time and save out the xarray to netcdf to compare w/ URMA\n",
    "extract_threshold = 0.254\n",
    "extract_interval = 24\n",
    "data_label = 'probx_%s_%02dh'%(str(extract_threshold).replace('.', 'p'), extract_interval)\n",
    "\n",
    "# Build a list of inits\n",
    "inits = pd.date_range(\n",
    "    datetime(2020, 6, 1, 0), \n",
    "    datetime(2020, 6, 10, 23), \n",
    "    freq='6H')\n",
    "\n",
    "outfile = '../scripts/' + data_label + '.%s_%s.WR.nc'%(\n",
    "    inits[0].strftime('%Y%m%d%H'), \n",
    "    inits[-1].strftime('%Y%m%d%H'))\n",
    "\n",
    "os.remove(outfile)\n",
    "\n",
    "if not os.path.isfile(outfile):\n",
    "\n",
    "    nbm_flist_agg = []\n",
    "    for init in inits:\n",
    "\n",
    "        try:\n",
    "            nbm_flist = sorted(glob(nbm_dir + init.strftime('%Y%m%d') + '/*t%02dz*'%init.hour))\n",
    "            nbm_flist[0]\n",
    "\n",
    "        except:\n",
    "            nbm_flist = sorted(glob(nbm_dir + init.strftime('%Y%m%d') + '/*t%02dz*'%(init+timedelta(hours=1)).hour))\n",
    "\n",
    "        nbm_flist = [f for f in nbm_flist if 'idx' not in f]\n",
    "\n",
    "        if len(nbm_flist) > 0:\n",
    "            nbm_flist_agg.append(nbm_flist)\n",
    "\n",
    "    nbm_flist_agg = np.hstack(nbm_flist_agg)\n",
    "\n",
    "    with pygrib.open(nbm_flist_agg[0]) as sample:\n",
    "        lat, lon = sample.message(1).latlons()\n",
    "    \n",
    "    unpack_fhr_mp = partial(unpack_fhr, xinterval=extract_interval, xthreshold=extract_threshold)\n",
    "\n",
    "    # 128 workers ~ 1.2GB RAM/worker\n",
    "    workers = 128\n",
    "    with mp.get_context('fork').Pool(workers) as p:\n",
    "        returns = p.map(unpack_fhr_mp, nbm_flist_agg, chunksize=1)\n",
    "        p.close()\n",
    "        p.join()\n",
    "\n",
    "    returns = np.array([r for r in returns if r is not None], dtype=object)\n",
    "    init = returns[:, 0].astype(np.datetime64)\n",
    "    valid = returns[:, 1].astype(np.datetime64).reshape(len(np.unique(init)), -1)\n",
    "    lead = returns[:, 2].astype(np.int16).reshape(len(np.unique(init)), -1)\n",
    "    data = np.array([r for r in returns[:, 3]], dtype=np.int8).reshape(len(np.unique(init)), -1, nbm_shape[0], nbm_shape[1])\n",
    "\n",
    "    valid = xr.DataArray(valid, name='valid', dims=('init', 'lead'), coords={'init':np.unique(init), 'lead':np.unique(lead)})\n",
    "    data = xr.DataArray(data, name=data_label, dims=('init', 'lead', 'y', 'x'), coords={'init':np.unique(init), 'lead':np.unique(lead)})\n",
    "    data = xr.merge([data, valid])\n",
    "\n",
    "    data['lat'] = xr.DataArray(lat, dims=('y', 'x'))\n",
    "    data['lon'] = xr.DataArray(lon, dims=('y', 'x'))\n",
    "    data.set_coords(['lat', 'lon'])\n",
    "    \n",
    "    data.to_netcdf(outfile)\n",
    "\n",
    "else:\n",
    "    data = xr.open_dataset(outfile)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_unique = np.unique([pd.to_datetime(t).strftime('%Y%m%d%H') for t in data['valid'].values])\n",
    "urma_flist = np.hstack([[f for f in glob(urma_dir + '*%s*.WR.grib2'%v) if 'idx' not in f] for v in valid_unique])\n",
    "print(urma_flist[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dataset(f, cfengine='pynio'):\n",
    "    \n",
    "    ds = xr.open_dataset(f, engine=cfengine)\n",
    "    ds['valid'] = datetime.strptime(f.split('/')[-1].split('.')[1], '%Y%m%d%H')\n",
    "    \n",
    "    return ds\n",
    "\n",
    "with mp.get_context('fork').Pool(int(len(urma_flist)/2)) as p:\n",
    "    urma = p.map(open_dataset, urma_flist)\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "urma = xr.concat(urma, dim='valid').rename({'APCP_P8_L1_GLC0_acc':'apcp6h', \n",
    "                                            'xgrid_0':'x', 'ygrid_0':'y',\n",
    "                                            'gridlat_0':'lat', 'gridlon_0':'lon'})\n",
    "urma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
