{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import urllib.request as req\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_csv(get_req, this, total):\n",
    "\n",
    "    _date, _init_hour, _url = get_req\n",
    "    \n",
    "    try:\n",
    "        response = req.urlopen(_url).read().decode('utf-8')\n",
    "        print('\\r[%d/%d] %s %s'%(this, total, _date, _init_hour), end='')\n",
    "        \n",
    "    except:\n",
    "        print('\\r[%d/%d] NOT FOUND %s %s'%(this, total, _date, _init_hour), end='')\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        init = datetime(_date.year, _date.month, _date.day, _init_hour, 0)\n",
    "\n",
    "        response = response.split('\\n')\n",
    "        header = np.append('InitTime', response[0].split(','))\n",
    "        \n",
    "        lines = []\n",
    "        for line in response[1:]:\n",
    "            line = line.split(',')\n",
    "\n",
    "            try:\n",
    "                line[0] = datetime.strptime(line[0], '%Y%m%d%H')\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                lines.append(np.append(init, line))\n",
    "                        \n",
    "        return header, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precip_obs(s, d0, d1):\n",
    "    import requests\n",
    "\n",
    "    # Tokens registered to michael.wessler@noaa.gov\n",
    "    api_token = 'a2386b75ecbc4c2784db1270695dde73'\n",
    "    api_key = 'Kyyki2tc1ETHUgShiscycW15e1XI02SzRXTYG28Dpg'\n",
    "    base = 'https://api.synopticdata.com/v2/stations/precip?'\n",
    "    \n",
    "    allints = []\n",
    "    \n",
    "    forecast_interval = 6\n",
    "    for interval in [6, 12, 24]:\n",
    "        \n",
    "        # Limit how big the observation lag can be (minutes)\n",
    "        lag_limit = (interval/2)*60\n",
    "        repeat = int((interval-forecast_interval)/6)+1\n",
    "        \n",
    "        df = []\n",
    "        while repeat > 0:\n",
    "            print('Working: Interval {}h Iteration {}'.format(interval, repeat))\n",
    "                        \n",
    "            _d0 = d0+timedelta(hours=(forecast_interval)*(repeat-1))\n",
    "            _d1 = d1+timedelta(hours=1+forecast_interval*(repeat-1))\n",
    "            \n",
    "            url = base + 'stid={}&start={}&end={}&pmode=intervals&interval={}&token={}'.format(\n",
    "                s,\n",
    "                datetime.strftime(_d0, '%Y%m%d%H%M'),\n",
    "                datetime.strftime(_d1, '%Y%m%d%H%M'),\n",
    "                interval, api_token)\n",
    "            \n",
    "            api_data_raw = requests.get(url).json()\n",
    "\n",
    "            vdates = pd.date_range(_d0, _d1, freq='%dh'%interval)\n",
    "            \n",
    "            for i in api_data_raw['STATION'][0]['OBSERVATIONS']['precipitation']:\n",
    "                \n",
    "                if i['last_report'] is not None:\n",
    "                    \n",
    "                    try:\n",
    "                        last_rep = datetime.strptime(i['last_report'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                        vtime = vdates[np.argmin(np.abs(vdates - last_rep))]\n",
    "                        lag_mins = (vtime - last_rep).seconds/60\n",
    "                        value = float(i['total']) if lag_mins < lag_limit else np.nan\n",
    "                    except:\n",
    "                        pass\n",
    "                    else:\n",
    "                        #print('{}\\t{}\\t{}\\t{}'.format(vtime, last_rep, lag_mins, value))\n",
    "                        df.append([vtime, last_rep, lag_mins, value])\n",
    "                    \n",
    "            repeat -= 1\n",
    "\n",
    "        allints.append(pd.DataFrame(df, \n",
    "            columns=['ValidTime', 'last_report', '%sh_lag_mins'%interval, '%sh_precip_mm'%interval]\n",
    "            ).set_index('ValidTime').sort_index())\n",
    "\n",
    "    return allints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBM 1D Viewer Site to use\n",
    "site = 'KMSO'\n",
    "vsite = 'KMSO' #expand to list of sties later on?\n",
    "init_hours = [1, 7, 13, 19] #[4, 16]\n",
    "\n",
    "datadir = './%s/data/'%site\n",
    "os.makedirs(datadir, exist_ok=True)\n",
    "\n",
    "figdir = './%s/figures/'%site\n",
    "os.makedirs(figdir, exist_ok=True)\n",
    "\n",
    "# Data Range\n",
    "date0 = datetime(2020, 2, 20)\n",
    "date1 = datetime(2020, 6, 20)\n",
    "dates = pd.date_range(date0, date1, freq='1D')\n",
    "\n",
    "lead = 263 #10d @ 240h\n",
    "date2 = date1 + timedelta(hours=lead)\n",
    "\n",
    "date0, date1, date2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obfile = datadir + '%s_obs_%s_%s.pd'%(site, date0.strftime('%Y%m%d'), date1.strftime('%Y%m%d'))\n",
    "\n",
    "if os.path.isfile(obfile):\n",
    "    # Load file\n",
    "    obs = pd.read_pickle(obfile)\n",
    "    print('Loaded obs from file %s'%obfile)\n",
    "\n",
    "else:\n",
    "    # Get and save file\n",
    "    obs = get_precip_obs(vsite, date0, date2)\n",
    "    obs = obs[0].merge(obs[1], how='inner', on='ValidTime').merge(obs[2], how='inner', on='ValidTime')\n",
    "    obs = obs[[k for k in obs.keys() if 'precip' in k]].sort_index()\n",
    "\n",
    "    obs.to_pickle(obfile)\n",
    "    print('Saved obs to file %s'%obfile)\n",
    "\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbmfile = datadir + '%s_nbm_%s_%s.pd'%(site, date0.strftime('%Y%m%d'), date1.strftime('%Y%m%d'))\n",
    "\n",
    "if os.path.isfile(nbmfile):\n",
    "    # Load file\n",
    "    nbm = pd.read_pickle(nbmfile)\n",
    "    print('Loaded NBM from file %s'%nbmfile)\n",
    "\n",
    "else:\n",
    "    url_list = []\n",
    "    for date in dates:\n",
    "        for init_hour in init_hours:\n",
    "            # For now pull from the csv generator\n",
    "            # Best to get API access or store locally later\n",
    "            base = 'https://hwp-viz.gsd.esrl.noaa.gov/wave1d/data/archive/'\n",
    "            datestr = '{:04d}/{:02d}/{:02d}'.format(date.year, date.month, date.day)\n",
    "            sitestr = '/NBM/{:02d}/{:s}.csv'.format(init_hour, site)\n",
    "            url_list.append([date, init_hour, base + datestr + sitestr])\n",
    "\n",
    "    # Try multiprocessing this for speed?\n",
    "    nbm = np.array([get_1d_csv(url, this=i+1, total=len(url_list)) for i, url in enumerate(url_list)])\n",
    "    nbm = np.array([line for line in nbm if line is not None])\n",
    "\n",
    "    header = nbm[0, 0]\n",
    "    \n",
    "    # This drops days with incomplete collections. There may be some use\n",
    "    # to keeping this data, can fix in the future if need be\n",
    "    # May also want to make the 100 value flexible!\n",
    "    nbm = np.array([np.array(line[1]) for line in nbm if len(line[1]) == 100])\n",
    "\n",
    "    nbm = nbm.reshape(-1, nbm.shape[-1])\n",
    "    nbm[np.where(nbm == '')] = np.nan\n",
    "\n",
    "    # Aggregate to a clean dataframe\n",
    "    nbm = pd.DataFrame(nbm, columns=header).set_index(\n",
    "        ['InitTime', 'ValidTime']).sort_index()\n",
    "\n",
    "    # Drop last column (misc metadata?)\n",
    "    nbm = nbm.iloc[:, :-2].astype(float)\n",
    "    header = nbm.columns\n",
    "\n",
    "    # variables = np.unique([k.split('_')[0] for k in header])\n",
    "    # levels = np.unique([k.split('_')[1] for k in header])\n",
    "\n",
    "    init =  nbm.index.get_level_values(0)\n",
    "    valid = nbm.index.get_level_values(1)\n",
    "\n",
    "    # Note the 1h 'fudge factor' in the lead time here\n",
    "    lead = pd.DataFrame(\n",
    "        np.transpose([init, valid, ((valid - init).values/3600/1e9).astype(int)+1]), \n",
    "        columns=['InitTime', 'ValidTime', 'LeadTime']).set_index(['InitTime', 'ValidTime'])\n",
    "\n",
    "    nbm.insert(0, 'LeadTime', lead)\n",
    "\n",
    "    klist = np.array([k for k in np.unique([k for k in list(nbm.keys())]) if ('APCP' in k)&('1hr' not in k)])\n",
    "    klist = klist[np.argsort(klist)]\n",
    "    klist = np.append('LeadTime', klist)\n",
    "    nbm = nbm.loc[:, klist]\n",
    "    \n",
    "    # Nix values where lead time shorter than acc interval\n",
    "    for k in nbm.keys():\n",
    "        if 'APCP24hr' in k:\n",
    "            nbm[k][nbm['LeadTime'] < 24] = np.nan\n",
    "        elif 'APCP12hr' in k:\n",
    "            nbm[k][nbm['LeadTime'] < 12] = np.nan\n",
    "        elif 'APCP6hr' in k:\n",
    "            nbm[k][nbm['LeadTime'] < 6] = np.nan\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    nbm.to_pickle(nbmfile)\n",
    "    print('\\nSaved NBM to file %s'%obfile)\n",
    "    \n",
    "nbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead12 = nbm[nbm['LeadTime'] == 12].reset_index().drop(columns='InitTime').set_index('ValidTime')\n",
    "pd.DataFrame(lead12['APCP12hr_surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(lead12['APCP6hr_surface_70% level']).merge(obs['6h_precip_mm'], on='ValidTime')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plev in [5, 30, 50, 70, 95]:\n",
    "\n",
    "    me = []\n",
    "    for fi in [6, 12, 24]:\n",
    "        _me = []\n",
    "        for lt in np.arange(6, 240+1, 6):\n",
    "            fk = 'APCP%dhr_surface_%d%% level'%(fi, plev) #'APCP%dhr_surface'%fi\n",
    "            vk = '%sh_precip_mm'%fi\n",
    "\n",
    "            fx = nbm[fk][nbm['LeadTime'] == lt].reset_index().drop(columns='InitTime').set_index('ValidTime')\n",
    "            vx = pd.DataFrame(fx).merge(obs[vk], on='ValidTime').dropna()\n",
    "\n",
    "            vx = vx[vx > 0]\n",
    "\n",
    "            # Mean error\n",
    "            _me.append((vx[fk] - vx[vk]).mean())\n",
    "\n",
    "        me.append(np.array(_me))\n",
    "\n",
    "    me = np.array(me)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(30, 6), facecolor='w')\n",
    "\n",
    "    cmap = plt.cm.bwr_r\n",
    "    cmap.set_bad('black',1.)\n",
    "\n",
    "    cbd = ax.pcolormesh(me, cmap=cmap, vmin=-10, vmax=10)\n",
    "    cb = plt.colorbar(cbd, ax=ax, orientation='horizontal', label='\\nAbsolute Error [mm]\\n\\nNaN Blacked Out')\n",
    "\n",
    "    ax.set_xlabel('\\nLead Time')\n",
    "    ax.set_xticks(np.arange(1, len(np.arange(6, 240+7, 6)))-.5)\n",
    "    ax.set_xticklabels(np.arange(6, 240+1, 6))\n",
    "\n",
    "    ax.set_ylabel('\\nAccumulation Interval')\n",
    "    ax.set_yticks([0.5, 1.5, 2.5])\n",
    "    ax.set_yticklabels([6, 12, 24])\n",
    "\n",
    "    plt.title('QPF Forecast Error for %s\\n\\np%d'%(site, plev))\n",
    "    \n",
    "    figname = '%s_p%s_meanerr.png'%(site, plev)\n",
    "    plt.savefig(figdir + figname)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = []\n",
    "for fi in [6, 12, 24]:\n",
    "    _me = []\n",
    "    for lt in np.arange(6, 240+1, 6):\n",
    "        fk = 'APCP%dhr_surface'%fi\n",
    "        vk = '%sh_precip_mm'%fi\n",
    "\n",
    "        fx = nbm[fk][nbm['LeadTime'] == lt].reset_index().drop(columns='InitTime').set_index('ValidTime')\n",
    "        vx = pd.DataFrame(fx).merge(obs[vk], on='ValidTime').dropna()\n",
    "\n",
    "        vx = vx[vx > 0]\n",
    "\n",
    "        # Mean error\n",
    "        _me.append((vx[fk] - vx[vk]).mean())\n",
    "\n",
    "    me.append(np.array(_me))\n",
    "\n",
    "me = np.array(me)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(30, 6), facecolor='w')\n",
    "\n",
    "cmap = plt.cm.bwr_r\n",
    "cmap.set_bad('black',1.)\n",
    "\n",
    "cbd = ax.pcolormesh(me, cmap=cmap, vmin=-10, vmax=10)\n",
    "cb = plt.colorbar(cbd, ax=ax, orientation='horizontal', label='\\nAbsolute Error [mm]\\n\\nNaN Blacked Out')\n",
    "\n",
    "ax.set_xlabel('\\nLead Time')\n",
    "ax.set_xticks(np.arange(1, len(np.arange(6, 240+7, 6)))-.5)\n",
    "ax.set_xticklabels(np.arange(6, 240+1, 6))\n",
    "\n",
    "ax.set_ylabel('\\nAccumulation Interval')\n",
    "ax.set_yticks([0.5, 1.5, 2.5])\n",
    "ax.set_yticklabels([6, 12, 24])\n",
    "\n",
    "plt.title('QPF Forecast Error for %s\\n'%(site))\n",
    "\n",
    "figname = '%s_meanerr.png'%(site)\n",
    "plt.savefig(figdir + figname)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
