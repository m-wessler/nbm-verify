{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run in Google CoLab! (Open in new window or new tab)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m-wessler/nbm-verify/blob/master/notebooks/verify_1Dqpf_dev.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import urllib.request as req\n",
    "\n",
    "import scipy.stats as scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nbm_funcs import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "colors = [\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#999999\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Configuration\n",
    "Select 'site' to evaluate, modify 'vsite' if an alternate verification site is preferred<br>\n",
    "Fixed 'date0' at the start of the NBM v3.2 period (2/20/2020)<br>\n",
    "Full lead time is 263 hours - Note if date1 is within this period, there will be missing verification data as it does not exist yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBM 1D Viewer Site to use\n",
    "site = 'KSEA'\n",
    "vsite = site\n",
    "\n",
    "# Data Range\n",
    "lead_time_end = 263\n",
    "init_hours = [13]#[1, 7, 13, 19]\n",
    "\n",
    "date0 = datetime(2020, 2, 20)\n",
    "date1 = datetime(2020, 7, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecast Site: KSEA\n",
      "Verif Site: KSEA\n",
      "Init Hours: [1, 7, 13, 19]\n",
      "First Init: 2020-02-20 00:00:00\n",
      "Last Init: 2020-07-08 00:00:00\n",
      "Last Verif: 2020-07-18 23:00:00\n"
     ]
    }
   ],
   "source": [
    "sitepath = site if site == vsite else '_'.join([site, vsite])\n",
    "\n",
    "datadir = '../archive/%s/data/'%sitepath\n",
    "os.makedirs(datadir, exist_ok=True)\n",
    "\n",
    "figdir = '../archive//%s/figures/'%sitepath\n",
    "os.makedirs(figdir, exist_ok=True)\n",
    "\n",
    "dates = pd.date_range(date0, date1, freq='1D')\n",
    "date2 = date1 + timedelta(hours=lead_time_end)\n",
    "\n",
    "print(('\\nForecast Site: {}\\nVerif Site: {}\\nInit Hours: '+\n",
    "      '{}\\nFirst Init: {}\\nLast Init: {}\\nLast Verif: {}').format(\n",
    "    site, vsite, init_hours, date0, date1, date2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Obtain observation data from SynopticLabs (MesoWest) API\n",
    "These are quality-controlled precipitation observations with adjustable accumulation periods<br>\n",
    "See more at: https://developers.synopticdata.com/mesonet/v2/stations/precipitation/\n",
    "<br><br>\n",
    "If no observation file exists, will download and save for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working: Interval 6h Iteration 1\n",
      "Working: Interval 12h Iteration 2\n",
      "Working: Interval 12h Iteration 1\n",
      "Working: Interval 24h Iteration 4\n",
      "Working: Interval 24h Iteration 3\n",
      "Working: Interval 24h Iteration 2\n",
      "Working: Interval 24h Iteration 1\n",
      "\n",
      "Saved obs to file ../archive/KSEA/data/KSEA_obs_20200220_20200708.pd\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6h_precip_in</th>\n",
       "      <td>580.0</td>\n",
       "      <td>0.018041</td>\n",
       "      <td>0.065351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12h_precip_in</th>\n",
       "      <td>580.0</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>0.105541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24h_precip_in</th>\n",
       "      <td>580.0</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.168010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.251969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count      mean       std  min  25%  50%   75%       max\n",
       "6h_precip_in   580.0  0.018041  0.065351  0.0  0.0  0.0  0.00  0.640000\n",
       "12h_precip_in  580.0  0.035662  0.105541  0.0  0.0  0.0  0.01  0.780000\n",
       "24h_precip_in  580.0  0.072906  0.168010  0.0  0.0  0.0  0.05  1.251969"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obfile = datadir + '%s_obs_%s_%s.pd'%(site, date0.strftime('%Y%m%d'), date1.strftime('%Y%m%d'))\n",
    "\n",
    "if os.path.isfile(obfile):\n",
    "    # Load file\n",
    "    obs = pd.read_pickle(obfile)\n",
    "    print('\\nLoaded obs from file %s\\n'%obfile)\n",
    "\n",
    "else:\n",
    "    # Get and save file\n",
    "    obs = get_precip_obs(vsite, date0, date2)\n",
    "    obs = obs[0].merge(obs[1], how='inner', on='ValidTime').merge(obs[2], how='inner', on='ValidTime')\n",
    "    obs = obs[[k for k in obs.keys() if 'precip' in k]].sort_index()\n",
    "\n",
    "    obs.to_pickle(obfile)\n",
    "    print('\\nSaved obs to file %s\\n'%obfile)\n",
    "    \n",
    "mm_in = 1/25.4\n",
    "obs *= mm_in\n",
    "[obs.rename(columns={k:k.replace('mm', 'in')}, inplace=True) for k in obs.keys()]\n",
    "\n",
    "obs.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the distribution of precipitation observations for assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KSEA_6h.observedAPCP.png\n",
      "KSEA_12h.observedAPCP.png\n",
      "KSEA_24h.observedAPCP.png\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "binsize = 0.05\n",
    "\n",
    "thresholds = {}\n",
    "for interval in [6, 12, 24]:\n",
    "        \n",
    "    iobs = obs['%dh_precip_in'%interval].values\n",
    "    iobs[iobs <= 0.01] = np.nan\n",
    "    \n",
    "    thresholds[interval] = np.nanpercentile(iobs, (33, 67))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6), facecolor='w')\n",
    "    \n",
    "    ax.hist(iobs, bins=np.arange(0, np.nanmax(iobs), binsize), \n",
    "            edgecolor='k', density=True, color='gray', alpha=0.75,\n",
    "            label='PDF (%.2f in bins)'%binsize)\n",
    "    \n",
    "    axx = ax.twinx()\n",
    "    axx.hist(iobs, bins=np.arange(0, np.nanmax(iobs), 0.00001), \n",
    "            density=True, cumulative=True, histtype='step', edgecolor='k', linewidth=2.5)\n",
    "    axx.plot(0, linewidth=2.5, color='k', label='CDF (Continuous)')\n",
    "    \n",
    "    for p, c in zip([33, 67], ['g', 'r']):\n",
    "        ax.axvline(np.nanpercentile(iobs, p), color=c, linewidth=3, zorder=-1, \n",
    "                   label='%dth Percentile: %.2f in'%(p, np.nanpercentile(iobs, p)))\n",
    "\n",
    "    ax.set_xticks(np.arange(0, np.nanmax(iobs)+1, binsize))\n",
    "    ax.set_xticklabels(['%.2f'%v for v in np.arange(0, np.nanmax(iobs)+1, binsize)], rotation=45)\n",
    "    \n",
    "    axx.set_ylabel('\\nCumulative [%]')\n",
    "    axx.set_yticks([0, .2, .4, .6, .8, 1.0])\n",
    "    axx.set_yticklabels([0, 20, 40, 60, 80, 100])\n",
    "    axx.set_ylim([0, 1.01])\n",
    "    \n",
    "    ax.set_xlim([0, np.nanmax(iobs)-0.05])\n",
    "    \n",
    "    ax.set_xlabel('\\n%dh Observed Accumulated Precipitation [in]'%interval)\n",
    "    ax.set_ylabel('Frequency [%]\\n')\n",
    "    ax.set_title('%s\\n%dh Observed Accumulated Precipitation\\nNBM v3.2 Period %s â€“ %s\\n'%(\n",
    "        site, interval, date0.strftime('%Y-%m-%d'), date2.strftime('%Y-%m-%d')))\n",
    "    \n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = axx.get_legend_handles_labels()\n",
    "    axx.legend(lines + lines2, labels + labels2, loc='center right')\n",
    "\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    savestr = '{}_{}h.observedAPCP.png'.format(site, interval)\n",
    "    print(savestr)\n",
    "    \n",
    "    os.makedirs(figdir + 'apcp_dist/', exist_ok=True)\n",
    "    plt.savefig(figdir + 'apcp_dist/' + savestr, dpi=150)\n",
    "    \n",
    "    plt.close()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Obtain NBM forecast data from NBM 1D Viewer (csv file API)\n",
    "These are the NBM 1D output files extracted from the viewer with 3 set accumulation periods<br>\n",
    "See more at: https://hwp-viz.gsd.esrl.noaa.gov/wave1d/?location=KSLC&col=2&hgt=1&obs=true&fontsize=1&selectedgroup=Default\n",
    "<br><br>\n",
    "If no forecast file exists, will download and save for future use. This can take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[560/560] 2020-07-08 00:00:00 190:00:00 13\n",
      "Saved NBM to file ../archive/KSEA/data/KSEA_obs_20200220_20200708.pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>APCP6hr_surface</th>\n",
       "      <td>21062.0</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>0.037579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APCP6hr_surface_70% level</th>\n",
       "      <td>21472.0</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>0.037770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.424961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APCP6hr_surface_50% level</th>\n",
       "      <td>21472.0</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APCP12hr_surface</th>\n",
       "      <td>20984.0</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>0.075421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033553</td>\n",
       "      <td>0.686614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APCP12hr_surface_70% level</th>\n",
       "      <td>20984.0</td>\n",
       "      <td>0.037218</td>\n",
       "      <td>0.070633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.044656</td>\n",
       "      <td>0.676181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APCP12hr_surface_50% level</th>\n",
       "      <td>20984.0</td>\n",
       "      <td>0.013878</td>\n",
       "      <td>0.040987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.490551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APCP24hr_surface</th>\n",
       "      <td>9736.0</td>\n",
       "      <td>0.075651</td>\n",
       "      <td>0.127154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.104469</td>\n",
       "      <td>0.806142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APCP24hr_surface_70% level</th>\n",
       "      <td>9736.0</td>\n",
       "      <td>0.091582</td>\n",
       "      <td>0.127745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033071</td>\n",
       "      <td>0.141663</td>\n",
       "      <td>0.818543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APCP24hr_surface_50% level</th>\n",
       "      <td>9736.0</td>\n",
       "      <td>0.044920</td>\n",
       "      <td>0.085533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.052224</td>\n",
       "      <td>0.630118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count      mean       std  min  25%       50%  \\\n",
       "APCP6hr_surface             21062.0  0.014014  0.037579  0.0  0.0  0.000000   \n",
       "APCP6hr_surface_70% level   21472.0  0.014956  0.037770  0.0  0.0  0.000000   \n",
       "APCP6hr_surface_50% level   21472.0  0.004676  0.020427  0.0  0.0  0.000000   \n",
       "APCP12hr_surface            20984.0  0.035931  0.075421  0.0  0.0  0.000000   \n",
       "APCP12hr_surface_70% level  20984.0  0.037218  0.070633  0.0  0.0  0.000827   \n",
       "APCP12hr_surface_50% level  20984.0  0.013878  0.040987  0.0  0.0  0.000000   \n",
       "APCP24hr_surface             9736.0  0.075651  0.127154  0.0  0.0  0.004587   \n",
       "APCP24hr_surface_70% level   9736.0  0.091582  0.127745  0.0  0.0  0.033071   \n",
       "APCP24hr_surface_50% level   9736.0  0.044920  0.085533  0.0  0.0  0.000354   \n",
       "\n",
       "                                 75%       max  \n",
       "APCP6hr_surface             0.000000  0.550000  \n",
       "APCP6hr_surface_70% level   0.008307  0.424961  \n",
       "APCP6hr_surface_50% level   0.000000  0.342520  \n",
       "APCP12hr_surface            0.033553  0.686614  \n",
       "APCP12hr_surface_70% level  0.044656  0.676181  \n",
       "APCP12hr_surface_50% level  0.001654  0.490551  \n",
       "APCP24hr_surface            0.104469  0.806142  \n",
       "APCP24hr_surface_70% level  0.141663  0.818543  \n",
       "APCP24hr_surface_50% level  0.052224  0.630118  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbmfile = datadir + '%s_nbm_%s_%s.pd'%(site, date0.strftime('%Y%m%d'), date1.strftime('%Y%m%d'))\n",
    "\n",
    "if os.path.isfile(nbmfile):\n",
    "    # Load file\n",
    "    nbm = pd.read_pickle(nbmfile)\n",
    "    print('Loaded NBM from file %s'%nbmfile)\n",
    "\n",
    "else:\n",
    "    url_list = []\n",
    "    for date in dates:\n",
    "        for init_hour in init_hours:\n",
    "            # For now pull from the csv generator\n",
    "            # Best to get API access or store locally later\n",
    "            base = 'https://hwp-viz.gsd.esrl.noaa.gov/wave1d/data/archive/'\n",
    "            datestr = '{:04d}/{:02d}/{:02d}'.format(date.year, date.month, date.day)\n",
    "            sitestr = '/NBM/{:02d}/{:s}.csv'.format(init_hour, site)\n",
    "            url_list.append([date, init_hour, base + datestr + sitestr])\n",
    "\n",
    "    # Try multiprocessing this for speed?\n",
    "    nbm = np.array([get_1d_csv(url, this=i+1, total=len(url_list)) for i, url in enumerate(url_list)])\n",
    "    nbm = np.array([line for line in nbm if line is not None])\n",
    "\n",
    "    header = nbm[0, 0]\n",
    "    \n",
    "    # This drops days with incomplete collections. There may be some use\n",
    "    # to keeping this data, can fix in the future if need be\n",
    "    # May also want to make the 100 value flexible!\n",
    "    nbm = np.array([np.array(line[1]) for line in nbm if len(line[1]) == 100])\n",
    "\n",
    "    nbm = nbm.reshape(-1, nbm.shape[-1])\n",
    "    nbm[np.where(nbm == '')] = np.nan\n",
    "\n",
    "    # Aggregate to a clean dataframe\n",
    "    nbm = pd.DataFrame(nbm, columns=header).set_index(\n",
    "        ['InitTime', 'ValidTime']).sort_index()\n",
    "\n",
    "    # Drop last column (misc metadata?)\n",
    "    nbm = nbm.iloc[:, :-2].astype(float)\n",
    "    header = nbm.columns\n",
    "\n",
    "    # variables = np.unique([k.split('_')[0] for k in header])\n",
    "    # levels = np.unique([k.split('_')[1] for k in header])\n",
    "\n",
    "    init =  nbm.index.get_level_values(0)\n",
    "    valid = nbm.index.get_level_values(1)\n",
    "\n",
    "    # Note the 1h 'fudge factor' in the lead time here\n",
    "    lead = pd.DataFrame(\n",
    "        np.transpose([init, valid, ((valid - init).values/3600/1e9).astype(int)+1]), \n",
    "        columns=['InitTime', 'ValidTime', 'LeadTime']).set_index(['InitTime', 'ValidTime'])\n",
    "\n",
    "    nbm.insert(0, 'LeadTime', lead)\n",
    "\n",
    "    klist = np.array([k for k in np.unique([k for k in list(nbm.keys())]) if ('APCP' in k)&('1hr' not in k)])\n",
    "    klist = klist[np.argsort(klist)]\n",
    "    klist = np.append('LeadTime', klist)\n",
    "    nbm = nbm.loc[:, klist]\n",
    "    \n",
    "    # Nix values where lead time shorter than acc interval\n",
    "    for k in nbm.keys():\n",
    "        if 'APCP24hr' in k:\n",
    "            nbm[k][nbm['LeadTime'] < 24] = np.nan\n",
    "        elif 'APCP12hr' in k:\n",
    "            nbm[k][nbm['LeadTime'] < 12] = np.nan\n",
    "        elif 'APCP6hr' in k:\n",
    "            nbm[k][nbm['LeadTime'] < 6] = np.nan\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    nbm.to_pickle(nbmfile)\n",
    "    print('\\nSaved NBM to file %s'%obfile)\n",
    "\n",
    "# Convert mm to in\n",
    "nbm = pd.DataFrame([nbm['LeadTime']] + [nbm[k] * mm_in for k in nbm.keys() if 'LeadTime' not in k]).T\n",
    "\n",
    "# Display some basic stats\n",
    "nbm.loc[:, ['APCP6hr_surface', 'APCP6hr_surface_70% level', 'APCP6hr_surface_50% level',\n",
    "            'APCP12hr_surface', 'APCP12hr_surface_70% level', 'APCP12hr_surface_50% level',\n",
    "            'APCP24hr_surface', 'APCP24hr_surface_70% level', 'APCP24hr_surface_50% level'\n",
    "            ]].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the distribution of precipitation forecasts for assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KSEA_6h.detForecastAPCP.png\n",
      "KSEA_12h.detForecastAPCP.png\n",
      "KSEA_24h.detForecastAPCP.png\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "binsize = 0.05\n",
    "\n",
    "thresholds = {}\n",
    "for interval in [6, 12, 24]:\n",
    "        \n",
    "    iobs = nbm['APCP%dhr_surface'%interval].values\n",
    "    iobs[iobs <= 0.01] = np.nan\n",
    "    \n",
    "    thresholds[interval] = np.nanpercentile(iobs, (33, 67))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6), facecolor='w')\n",
    "    \n",
    "    ax.hist(iobs, bins=np.arange(0, np.nanmax(iobs), binsize), \n",
    "            edgecolor='k', density=True, color='gray', alpha=0.75,\n",
    "            label='PDF (%.2f in bins)'%binsize)\n",
    "    \n",
    "    axx = ax.twinx()\n",
    "    axx.hist(iobs, bins=np.arange(0, np.nanmax(iobs), 0.00001), \n",
    "            density=True, cumulative=True, histtype='step', edgecolor='k', linewidth=2.5)\n",
    "    axx.plot(0, linewidth=2.5, color='k', label='CDF (Continuous)')\n",
    "    \n",
    "    for p, c in zip([33, 67], ['g', 'r']):\n",
    "        ax.axvline(np.nanpercentile(iobs, p), color=c, linewidth=3, zorder=-1, \n",
    "                   label='%dth Percentile: %.2f in'%(p, np.nanpercentile(iobs, p)))\n",
    "\n",
    "    ax.set_xticks(np.arange(0, np.nanmax(iobs)+1, binsize))\n",
    "    ax.set_xticklabels(['%.2f'%v for v in np.arange(0, np.nanmax(iobs)+1, binsize)], rotation=45)\n",
    "    \n",
    "    axx.set_ylabel('\\nCumulative [%]')\n",
    "    axx.set_yticks([0, .2, .4, .6, .8, 1.0])\n",
    "    axx.set_yticklabels([0, 20, 40, 60, 80, 100])\n",
    "    axx.set_ylim([0, 1.01])\n",
    "    \n",
    "    ax.set_xlim([0, np.nanmax(iobs)-0.05])\n",
    "    \n",
    "    ax.set_xlabel('\\n%dh Forecast Precipitation [in]'%interval)\n",
    "    ax.set_ylabel('Frequency [%]\\n')\n",
    "    ax.set_title('%s\\n%dh Forecast Precipitation\\nNBM v3.2 Period %s â€“ %s\\n'%(\n",
    "        site, interval, date0.strftime('%Y-%m-%d'), date2.strftime('%Y-%m-%d')))\n",
    "    \n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = axx.get_legend_handles_labels()\n",
    "    axx.legend(lines + lines2, labels + labels2, loc='center right')\n",
    "    \n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    savestr = '{}_{}h.detForecastAPCP.png'.format(site, interval)\n",
    "    print(savestr)\n",
    "    \n",
    "    os.makedirs(figdir + 'apcp_dist/', exist_ok=True)\n",
    "    plt.savefig(figdir + 'apcp_dist/' + savestr, dpi=150)\n",
    "    \n",
    "    plt.close()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KSEA_6h.APCP_dist.png\n",
      "KSEA_12h.APCP_dist.png\n",
      "KSEA_24h.APCP_dist.png\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "binsize = 0.05\n",
    "\n",
    "thresholds = {}\n",
    "for interval in [6, 12, 24]:\n",
    "        \n",
    "    iobs = obs['%dh_precip_in'%interval]\n",
    "    iobs[iobs <= 0.01] = np.nan\n",
    "    \n",
    "    ifx = nbm['APCP%dhr_surface'%interval]\n",
    "    ifx[ifx <= 0.01] = np.nan\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 6), facecolor='w')\n",
    "    ax, axx = axs\n",
    "    \n",
    "    maxval = max(np.nanmax(iobs), np.nanmax(iobs))\n",
    "    \n",
    "    ax.hist(iobs, bins=np.arange(0, maxval, binsize), \n",
    "            edgecolor='k', density=True, color=colors[0], alpha=0.75,\n",
    "            label='Observed PDF (%.2f in bins)'%binsize)\n",
    "    \n",
    "    ax.hist(ifx, bins=np.arange(0, maxval, binsize), \n",
    "        edgecolor='k', density=True, color=colors[1], alpha=0.75,\n",
    "        label='Forecast PDF (%.2f in bins)'%binsize)\n",
    "    \n",
    "    axx.hist(iobs, bins=np.arange(0, maxval, 0.00001), \n",
    "            density=True, cumulative=True, histtype='step', \n",
    "            linewidth=2.5, edgecolor=colors[0])\n",
    "    axx.plot(0, linewidth=2.5, color=colors[0], label='Observed CDF (Continuous)')\n",
    "    \n",
    "    axx.hist(ifx, bins=np.arange(0, maxval, 0.00001), \n",
    "            density=True, cumulative=True, histtype='step', \n",
    "            linewidth=2.5, linestyle='-', edgecolor=colors[1])\n",
    "    axx.plot(0, linewidth=2.5, linestyle='-', color=colors[1], label='Forecast CDF (Continuous)')\n",
    "    \n",
    "    for p, c in zip([33, 67], [colors[4], colors[5]]):\n",
    "        ax.axvline(np.nanpercentile(iobs, p), color=c, linewidth=3, zorder=100, \n",
    "                   label='%dth Percentile Obs: %.2f in'%(p, np.nanpercentile(iobs, p)))\n",
    "    \n",
    "    axx.set_ylabel('\\nCumulative [%]')\n",
    "    axx.set_yticks([0, .2, .4, .6, .8, 1.0])\n",
    "    axx.set_yticklabels([0, 20, 40, 60, 80, 100])\n",
    "    axx.set_ylim([0, 1.01])\n",
    "        \n",
    "    for axi in axs:\n",
    "        axi.set_xticks(np.arange(0, maxval+binsize, binsize*2))\n",
    "        axi.set_xticklabels(['%.2f'%v for v in np.arange(0, maxval+binsize, binsize*2)], rotation=45)\n",
    "        axi.set_xlim([0, maxval-binsize])\n",
    "        axi.set_xlabel('\\n%dh Forecast Precipitation [in]'%interval)\n",
    "        \n",
    "        axi.set_ylabel('Frequency [%]\\n')\n",
    "        \n",
    "        axi.set_title('%s\\n%dh Forecast Precipitation\\nNBM v3.2 Period %s â€“ %s\\n'%(\n",
    "            site, interval, date0.strftime('%Y-%m-%d'), date2.strftime('%Y-%m-%d')))\n",
    "        \n",
    "        axi.grid(True)\n",
    "        \n",
    "    ax.legend(loc='upper right')\n",
    "    axx.legend(loc='lower right')\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    savestr = '{}_{}h.APCP_dist.png'.format(site, interval)\n",
    "    print(savestr)\n",
    "    \n",
    "    os.makedirs(figdir + 'apcp_dist/', exist_ok=True)\n",
    "    plt.savefig(figdir + 'apcp_dist/' + savestr, dpi=150)\n",
    "    \n",
    "    plt.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Reorganize the data for analysis:\n",
    "#### Isolate the forecasts by accumulation interval and lead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing interval 24 lead 258h\n",
      "\n",
      "Available keys:\n",
      "\t\tInterval\n",
      "\t\tLeadTime\n",
      "\t\tValidTime\n",
      "\t\tEventSize\n",
      "\t\tverif_ob\n",
      "\t\tdet_fx\n",
      "\t\tdet_rank\n",
      "\t\tdet_error\n",
      "\t\tverif_rank\n",
      "\t\tverif_rank_val\n",
      "\t\tverif_rank_error\n",
      "\t\tmed_fx\n",
      "\t\tmean_fx\n",
      "\t\tstd_fx\n",
      "n rows: 14815\n"
     ]
    }
   ],
   "source": [
    "# Event size thresholds \n",
    "# Use fixed override if desired else \n",
    "# 33rd, 67th percentile determined above\n",
    "thresholds = {\n",
    "    6:[.1, .25],\n",
    "    12:[.25, .5],\n",
    "    24:[.5, .75]}\n",
    "\n",
    "threshold_sets = [\n",
    "    [0, thresholds[interval][0]], \n",
    "    [thresholds[interval][0], thresholds[interval][1]], \n",
    "    [thresholds[interval][1], np.ceil(np.nanmax(obs))],\n",
    "    [np.nan, np.nan]]\n",
    "\n",
    "plist = np.arange(1, 100)\n",
    "\n",
    "data = []\n",
    "for interval in [6, 12, 24]:\n",
    "    \n",
    "    pkeys = np.array([k for k in nbm.keys() if '%dhr_'%interval in k])\n",
    "    pkeys = np.array([k for k in pkeys if '%' in k])\n",
    "    pkeys = pkeys[np.argsort([int(k.split('_')[-1].split('%')[0]) for k in pkeys])]\n",
    "    \n",
    "    for lead_time in np.arange(interval, lead_time_end, 6):\n",
    "        \n",
    "        for thresh, esize in zip(threshold_sets, ['Small', 'Medium', 'Large']):\n",
    "        \n",
    "            print('\\rProcessing interval %d lead %dh'%(interval, lead_time), end='')\n",
    "\n",
    "            # We need to break out the verification to each lead time,\n",
    "            # but within each lead time we have a number of valid times.\n",
    "            # At each lead time, valid time, isolate the forecast verification\n",
    "\n",
    "            # Combine the datasets to make it easier to work with\n",
    "            idata = nbm[nbm['LeadTime'] == lead_time].merge(obs, on='ValidTime').drop(columns='LeadTime')\n",
    "\n",
    "            # Subset for event size\n",
    "            iobs = idata['%dh_precip_in'%interval]\n",
    "            idata = idata[((iobs >= thresh[0]) & (iobs < thresh[1]))]\n",
    "                \n",
    "            for itime in idata.index:\n",
    "\n",
    "                try:\n",
    "                    prob_fx = idata.loc[itime, pkeys].values\n",
    "                    mean_fx = np.nanmean(prob_fx)\n",
    "                    std_fx = np.nanstd(prob_fx)\n",
    "                    med_fx = idata.loc[itime, 'APCP%dhr_surface_50%% level'%interval]\n",
    "                    det_fx = idata.loc[itime, 'APCP%dhr_surface'%interval]\n",
    "\n",
    "                    # Optional - leave as nan?\n",
    "                    det_fx = det_fx if ~np.isnan(det_fx) else 0.\n",
    "\n",
    "                    verif_ob = idata.loc[itime, '%dh_precip_in'%interval]\n",
    "                    verif_rank = np.searchsorted(prob_fx, verif_ob, 'right')\n",
    "                    verif_rank_val = prob_fx[verif_rank-1]\n",
    "                    verif_rank_error = verif_rank_val - verif_ob\n",
    "\n",
    "                    det_rank = np.searchsorted(prob_fx, det_fx, 'right')\n",
    "                    det_error = det_fx - verif_ob\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "                    # print('failed', itime)\n",
    "\n",
    "                else:\n",
    "                    if ((verif_ob > 0.)):\n",
    "\n",
    "                        data.append([\n",
    "                            # Indexers\n",
    "                            interval, lead_time, itime, esize,\n",
    "\n",
    "                            # Verification and deterministic\n",
    "                            verif_ob, det_fx, det_rank, det_error,\n",
    "\n",
    "                            # Probabilistic\n",
    "                            verif_rank, verif_rank_val, verif_rank_error, \n",
    "                            med_fx, mean_fx, std_fx])\n",
    "\n",
    "data = pd.DataFrame(data, columns=['Interval', 'LeadTime', 'ValidTime', 'EventSize',\n",
    "                'verif_ob', 'det_fx', 'det_rank', 'det_error',\n",
    "                'verif_rank', 'verif_rank_val', 'verif_rank_error', \n",
    "                'med_fx', 'mean_fx', 'std_fx'])\n",
    "\n",
    "print('\\n\\nAvailable keys:\\n\\t\\t{}\\nn rows: {}'.format('\\n\\t\\t'.join(data.keys()), len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>LeadTime</th>\n",
       "      <th>ValidTime</th>\n",
       "      <th>EventSize</th>\n",
       "      <th>verif_ob</th>\n",
       "      <th>det_fx</th>\n",
       "      <th>det_rank</th>\n",
       "      <th>det_error</th>\n",
       "      <th>verif_rank</th>\n",
       "      <th>verif_rank_val</th>\n",
       "      <th>verif_rank_error</th>\n",
       "      <th>med_fx</th>\n",
       "      <th>mean_fx</th>\n",
       "      <th>std_fx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-29 06:00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.110394</td>\n",
       "      <td>60</td>\n",
       "      <td>0.020394</td>\n",
       "      <td>50</td>\n",
       "      <td>0.089606</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>0.089606</td>\n",
       "      <td>0.091095</td>\n",
       "      <td>0.061968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-29 12:00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.012441</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.017559</td>\n",
       "      <td>54</td>\n",
       "      <td>0.029882</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.021969</td>\n",
       "      <td>0.041147</td>\n",
       "      <td>0.046711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-01 06:00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.031142</td>\n",
       "      <td>81</td>\n",
       "      <td>-0.058858</td>\n",
       "      <td>96</td>\n",
       "      <td>0.088504</td>\n",
       "      <td>-0.001496</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.015208</td>\n",
       "      <td>0.027523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-03 18:00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>98</td>\n",
       "      <td>0.033740</td>\n",
       "      <td>-0.016260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.009670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-06 18:00:00</td>\n",
       "      <td>Small</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.079094</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.100906</td>\n",
       "      <td>96</td>\n",
       "      <td>0.176260</td>\n",
       "      <td>-0.003740</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>0.052170</td>\n",
       "      <td>0.053932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14810</th>\n",
       "      <td>24</td>\n",
       "      <td>258</td>\n",
       "      <td>2020-04-23 12:00:00</td>\n",
       "      <td>Large</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.770000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14811</th>\n",
       "      <td>24</td>\n",
       "      <td>258</td>\n",
       "      <td>2020-05-31 06:00:00</td>\n",
       "      <td>Large</td>\n",
       "      <td>1.070984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.070984</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812</th>\n",
       "      <td>24</td>\n",
       "      <td>258</td>\n",
       "      <td>2020-05-31 12:00:00</td>\n",
       "      <td>Large</td>\n",
       "      <td>1.251969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.251969</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14813</th>\n",
       "      <td>24</td>\n",
       "      <td>258</td>\n",
       "      <td>2020-05-31 18:00:00</td>\n",
       "      <td>Large</td>\n",
       "      <td>0.983937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.983937</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14814</th>\n",
       "      <td>24</td>\n",
       "      <td>258</td>\n",
       "      <td>2020-06-28 12:00:00</td>\n",
       "      <td>Large</td>\n",
       "      <td>0.780984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.780984</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14815 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Interval  LeadTime           ValidTime EventSize  verif_ob    det_fx  \\\n",
       "0             6         6 2020-02-29 06:00:00     Small  0.090000  0.110394   \n",
       "1             6         6 2020-02-29 12:00:00     Small  0.030000  0.012441   \n",
       "2             6         6 2020-03-01 06:00:00     Small  0.090000  0.031142   \n",
       "3             6         6 2020-03-03 18:00:00     Small  0.050000  0.000000   \n",
       "4             6         6 2020-03-06 18:00:00     Small  0.180000  0.079094   \n",
       "...         ...       ...                 ...       ...       ...       ...   \n",
       "14810        24       258 2020-04-23 12:00:00     Large  0.770000  0.000000   \n",
       "14811        24       258 2020-05-31 06:00:00     Large  1.070984  0.000000   \n",
       "14812        24       258 2020-05-31 12:00:00     Large  1.251969  0.000000   \n",
       "14813        24       258 2020-05-31 18:00:00     Large  0.983937  0.000000   \n",
       "14814        24       258 2020-06-28 12:00:00     Large  0.780984  0.000000   \n",
       "\n",
       "       det_rank  det_error  verif_rank  verif_rank_val  verif_rank_error  \\\n",
       "0            60   0.020394          50        0.089606         -0.000394   \n",
       "1            43  -0.017559          54        0.029882         -0.000118   \n",
       "2            81  -0.058858          96        0.088504         -0.001496   \n",
       "3            54  -0.050000          98        0.033740         -0.016260   \n",
       "4            74  -0.100906          96        0.176260         -0.003740   \n",
       "...         ...        ...         ...             ...               ...   \n",
       "14810         0  -0.770000           0             NaN               NaN   \n",
       "14811         0  -1.070984           0             NaN               NaN   \n",
       "14812         0  -1.251969           0             NaN               NaN   \n",
       "14813         0  -0.983937           0             NaN               NaN   \n",
       "14814         0  -0.780984           0             NaN               NaN   \n",
       "\n",
       "         med_fx   mean_fx    std_fx  \n",
       "0      0.089606  0.091095  0.061968  \n",
       "1      0.021969  0.041147  0.046711  \n",
       "2      0.000394  0.015208  0.027523  \n",
       "3      0.000000  0.003588  0.009670  \n",
       "4      0.037323  0.052170  0.053932  \n",
       "...         ...       ...       ...  \n",
       "14810       NaN       NaN       NaN  \n",
       "14811       NaN       NaN       NaN  \n",
       "14812       NaN       NaN       NaN  \n",
       "14813       NaN       NaN       NaN  \n",
       "14814       NaN       NaN       NaN  \n",
       "\n",
       "[14815 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Create Bulk Temporal Stats Plots\n",
    "#### Reliability diagrams, bias over time, rank over time, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a pairplot for a basic overview of how certain metrics are correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval in [6, 12, 24]:\n",
    "    \n",
    "    for short, long in zip([0, 120], [120, 240]):\n",
    "        \n",
    "        for plot_type, plot_var in zip(\n",
    "            ['Verification', 'Comparison'], \n",
    "            ['verif_rank', 'det_rank']):\n",
    "            \n",
    "            for ei, esize in enumerate(['Small', 'Medium', 'Large', 'All']):\n",
    "\n",
    "                select = data[((data['Interval'] == interval)\n",
    "                            & ((data['LeadTime'] >= short) \n",
    "                            & (data['LeadTime'] <= long)))]\n",
    "\n",
    "                select = select[select['EventSize'] == esize] if esize != 'All' else select\n",
    "\n",
    "                try:\n",
    "                    pairplot = sns.pairplot(select, dropna=True, corner=True,\n",
    "                                vars=['verif_rank', 'verif_rank_val', 'verif_rank_error', \n",
    "                                      'det_fx', 'med_fx', 'mean_fx',  'LeadTime', 'verif_ob'])\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                else:\n",
    "                    savestr = '{}_{}h_sz{}_lead{}-{}h.pairplot.{}.png'.format(site, interval, esize, short, long, plot_type.lower())\n",
    "                    print(savestr)\n",
    "\n",
    "                    os.makedirs(figdir + 'pairplot/', exist_ok=True)\n",
    "                    plt.savefig(figdir + 'pairplot/' + savestr)\n",
    "                    \n",
    "                    plt.close()\n",
    "                    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a reliability diagram style CDF to evaluate percentile rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval in [6, 12, 24]:\n",
    "\n",
    "    for short, long in zip([0, 120], [120, 240]):\n",
    "\n",
    "        for plot_type, plot_var in zip(\n",
    "            ['Verification', 'Comparison'], \n",
    "            ['verif_rank', 'det_rank']):\n",
    "\n",
    "            for ei, esize in enumerate(['Small', 'Medium', 'Large', 'All']):\n",
    "                \n",
    "                select = data[((data['Interval'] == interval)\n",
    "                            & ((data['LeadTime'] >= short) \n",
    "                            & (data['LeadTime'] <= long)))]\n",
    "                \n",
    "                select = select[select['EventSize'] == esize] if esize != 'All' else select\n",
    "\n",
    "                # Produce the actual reliability diagram\n",
    "                font_size = 16\n",
    "                plt.rcParams.update({'font.size': font_size})\n",
    "                fig, ax = plt.subplots(1, figsize=(10, 10), facecolor='w')\n",
    "\n",
    "                pbins = np.arange(0, 101, 5)\n",
    "\n",
    "                ax.hist(select[plot_var], bins=pbins, density=True, cumulative=True, histtype='step',\n",
    "                        color='k', edgecolor='k', linewidth=3.5, zorder=10)\n",
    "\n",
    "                ax.hist(select[plot_var], bins=pbins, density=True, cumulative=True,\n",
    "                        color='0.75', linewidth=3.5, zorder=10, label='QPF %s At/Below'%plot_type)\n",
    "\n",
    "                ax.plot(np.arange(0, 101, 1), np.arange(0, 1.01, .01), '--k', linewidth=2, zorder=20)\n",
    "\n",
    "                try:\n",
    "                    ax.axvline(np.nanmean(select[plot_var]), color='g', linewidth=2, \n",
    "                               zorder=200, label='Mean: %d'%np.nanmean(select[plot_var]))\n",
    "\n",
    "                    ax.axvline(np.nanpercentile(select[plot_var], 50), color='r', linewidth=2, \n",
    "                               zorder=200, label='Median: %d'%np.nanpercentile(select[plot_var], 50))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                ax.set_xticks(np.arange(0, 101, 10))\n",
    "                ax.set_xlim([0, 100])\n",
    "                ax.set_xlabel('\\nForecast Percentile')\n",
    "\n",
    "                ax.set_yticks(np.arange(0, 1.01, .1))\n",
    "                ax.set_yticklabels(np.arange(0, 101, 10))\n",
    "                ax.set_ylim([0, 1.01])\n",
    "                ax.set_ylabel('%s Frequency\\n'%plot_type)\n",
    "\n",
    "                ax.set_title(('{} Percentile-Matched {}\\nNBM v3.2 {} â€“ {}\\n\\nEvent Size: {} ({} â€“ {} in)\\n'+\n",
    "                              'Interval: {} h | Lead Time: {} â€“ {} h | n={}\\n').format(\n",
    "                            site, plot_type, date0.strftime('%Y-%m-%d'), date1.strftime('%Y-%m-%d'),\n",
    "                            esize, threshold_sets[ei][0], threshold_sets[ei][1],\n",
    "                            interval, short, long, len(select)), size=font_size)\n",
    "\n",
    "                ax.legend(loc='upper left')\n",
    "                ax.grid()\n",
    "                plt.tight_layout()\n",
    "\n",
    "                savestr = '{}_{}h_sz{}_lead{}-{}h.reliabilityCDF.{}.png'.format(site, interval, esize, short, long, plot_type.lower())\n",
    "                print(savestr)\n",
    "\n",
    "                os.makedirs(figdir + 'reliabilityCDF/', exist_ok=True)\n",
    "                plt.savefig(figdir + 'reliabilityCDF/' + savestr, dpi=150)\n",
    "                \n",
    "                plt.close()\n",
    "                # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce a true reliability diagram along with error histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval in [6, 12, 24]:\n",
    "\n",
    "    for short, long in zip([0, 120], [120, 240]):\n",
    "\n",
    "        for plot_type, plot_var in zip(\n",
    "            ['Deterministic', 'Median', 'Mean'],\n",
    "            ['det_fx', 'med_fx', 'mean_fx']):\n",
    "\n",
    "            for ei, esize in enumerate(['Small', 'Medium', 'Large', 'All']):\n",
    "                esize = None if esize == 'All' else esize\n",
    "\n",
    "                select = data[((data['Interval'] == interval)\n",
    "                            & ((data['LeadTime'] >= short) \n",
    "                            & (data['LeadTime'] <= long)))]\n",
    "                \n",
    "                select = select[select['EventSize'] == esize] if esize != 'All' else select\n",
    "\n",
    "                try:\n",
    "                    max_val = max(np.nanmax(select['verif_ob']), np.nanmax(select[plot_var]))\n",
    "                    max_val = np.ceil(max_val*10)/10\n",
    "                    max_val = max_val if max_val >= threshold_sets[ei][1] else threshold_sets[ei][1]\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                else:\n",
    "                    # Produce the actual reliability diagram\n",
    "                    font_size = 16\n",
    "                    plt.rcParams.update({'font.size': font_size})\n",
    "\n",
    "                    fig, axs = plt.subplots(1, 2, figsize=(20, 10), facecolor='w')\n",
    "\n",
    "                    ax = axs[0]                \n",
    "\n",
    "                    ax.scatter(select['verif_ob'], select[plot_var], c='k', s=150, marker='+', linewidth=0.5, \n",
    "                               label='Forecasts')\n",
    "\n",
    "                    ax.plot(np.arange(0, max_val+.1, .1), np.arange(0, max_val+.1, .1), '--', label='Perfect Forecast')\n",
    "\n",
    "                    \n",
    "                    ax.set_xlim([0, max_val])\n",
    "                    ax.set_xlabel('\\nObserved QPF')\n",
    "\n",
    "                    ax.set_ylim([0, max_val])\n",
    "                    ax.set_ylabel('Forecast QPF\\n')\n",
    "\n",
    "                    ax = axs[1]\n",
    "\n",
    "                    ax.hist(select[plot_var] - select['verif_ob'], bins=np.arange(-0.5, .51, .05), density=True,\n",
    "                            color='0.45', edgecolor='k', linewidth=1, zorder=10, label='Forecast Error')\n",
    "\n",
    "                    ax.axvline(0, c='C0', linestyle='--', linewidth=2.5, zorder=10)\n",
    "                    \n",
    "                    ax.set_xlabel('Forecast Error')\n",
    "                    ax.set_ylabel('Error Frequency [% of Forecasts]')\n",
    "\n",
    "                    for ax in axs:\n",
    "                        ax.legend(loc='upper left')\n",
    "                        ax.grid()\n",
    "\n",
    "                    plt.suptitle(('{} {} Verification\\nNBM v3.2 {} â€“ {}\\n\\nEvent Size: {} ({} â€“ {} in)\\n'+\n",
    "                                  'Interval: {} h | Lead Time: {} â€“ {} h | n={}\\n').format(\n",
    "                                site, plot_type, date0.strftime('%Y-%m-%d'), date1.strftime('%Y-%m-%d'),\n",
    "                                esize, threshold_sets[ei][0], threshold_sets[ei][1],\n",
    "                                interval, short, long, len(select)), size=font_size)\n",
    "\n",
    "                    plt.tight_layout(rect=[0, 0.03, 1, 0.87])\n",
    "\n",
    "                    savestr = '{}_{}h_sz{}_lead{}-{}h.reliability_errhist.{}.png'.format(site, interval, esize, short, long, plot_type.lower())\n",
    "                    print(savestr)\n",
    "                    \n",
    "                    os.makedirs(figdir + 'reliability_errhist/', exist_ok=True)\n",
    "                    plt.savefig(figdir + 'reliability_errhist/' + savestr, dpi=150)\n",
    "                    \n",
    "                    plt.close()\n",
    "                    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce bias, ME, MAE, and percentile rank plots as they evolve over time\n",
    "This helps illustrate at what leads a dry/wet bias may exist and how severe it may be<br>\n",
    "Adds value in interpreting the CDF reliability diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
